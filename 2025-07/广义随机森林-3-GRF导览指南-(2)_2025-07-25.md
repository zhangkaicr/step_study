
### 基于树的策略学习
在本节中，我们将介绍如何使用 GRF 的姐妹包 [policytree](https://github.com/grf-labs/policytree)来构建基于树的干预策略。由于排序加权平均处理效应（RATE）表明，部分人群从该教育项目中获益较少（例如那些已具备高度 “财务自主性” 的学生），因此我们将尝试通过数据自适应算法，基于亚组来分配处理（干预）。一种实现方式是假设：应通过一个简单且可解释的、基于协变量的规则来决定项目参与资格。这正是`policytree`的功能 —— 它通过构建一棵浅层决策树来实现这一点，该决策树的目标是最大化遵循这种处理分配政策所带来的经验 “收益”。

用$\pi(X_i)$表示一个函数（策略）它接受协变量向量$X_i$并将其映射为一个二元决策，即决定研究对象是否应接受处理：$\pi \mapsto \{0, 1\}$ (这可以很轻松地扩展到多处理情形)。找到这种策略的任务被称为策略学习。 给定经验 “收益分数”$\hat \Gamma_i$, `policytree`会找到一个基于树的策略$\pi(X_i)$使其最大化

$$\frac{1}{n} \sum_{i=1}^{n} (2\pi(X_i) - 1)\hat \Gamma_i.$$
(关于 “2” 的来源说明：由于$\pi \in \{0, 1\}$，那么$2\pi - 1 \in \{-1, 1\}$，也就是说，当我们对个体$i$进行处理时，目标函数增加$\hat \Gamma_i$，当不对个体$i$进行处理时，目标函数减少$\hat \Gamma_i$。

下面我们将通过一个示例，介绍如何使用`policytree`包中的[policy_tree](https://grf-labs.github.io/policytree/reference/policy_tree.html) 函数来寻找一个最优的深度为 2 的决策树策略。该函数使用 C++ 求解器来找到一个浅层且最优的决策规则[5]。我们将使用不同的数据集来拟合和评估该政策：

```{r}

# 利用上面已经划分好的训练集和评估集（按学校划分），但仅选取特征变量无缺失值的样本用于策略树建模
# 获取评估集的样本索引，即从全部样本索引中排除训练集的索引
eval <- (1:nrow(X))[-train]
# 找出特征变量 X 中所有无缺失值的样本的索引
not.missing <- which(complete.cases(X))
# 筛选训练集，仅保留特征变量无缺失值的样本索引
train <- train[which(train %in% not.missing)]
# 筛选评估集，仅保留特征变量无缺失值的样本索引
eval <- eval[which(eval %in% not.missing)]

# 计算双重稳健分数（doubly robust scores），用于后续策略树的奖励计算
dr.scores <- get_scores(cf)
# 将之前计算得到的平均处理效应（ATE）作为项目处理的 “成本”，以找到有意义的策略
cost <- ate[["estimate"]]
# 计算控制组和处理组的奖励，控制组奖励为负的双重稳健分数，处理组奖励为双重稳健分数减去成本
dr.rewards <- cbind(control=-dr.scores, treat=dr.scores - cost)

# 在训练子集上拟合深度为 2 的策略树模型，设置每个叶子节点的最小样本量为 100
tree <- policy_tree(X[train, ], dr.rewards[train, ], min.node.size = 100)
# 绘制拟合好的策略树，为叶子节点添加标签，分别表示 “不处理” 和 “处理”
plot(tree, leaf.labels = c("dont treat", "treat"))

```
![](https://files.mdnice.com/user/91634/fcac27be-7bbf-46b8-9a82-2292b6845d3e.png)


拟合出的规则显然能够在样本中区分出那些从该程序中获益超过平均水平的单元。为了评估其统计有效性，我们应当在一个预留的数据集上对其进行检验，而在这个预留数据集上，该规则给出的平均收益未必会与样本中的相同。

```{r}
pi.hat <- predict(tree, X[eval,]) - 1
mean((dr.scores[eval] - cost) * (2*pi.hat - 1))
```
我们可以将平均处理效应（ATE）按照决策树划分的亚组进行分解，并在预留样本中考察关键统计量——例如扣除成本后的净平均处理效应。

```{r}

# 对评估集数据使用策略树模型进行预测，并将预测结果减 1，得到处理策略的预测值
pi.hat <- predict(tree, X[eval,]) - 1
# 计算评估集上基于预测策略的平均奖励，其中 dr.scores[eval] 为评估集的双重稳健分数，cost 为项目处理成本
mean((dr.scores[eval] - cost) * (2*pi.hat - 1))

# 预测评估集样本所在的叶子节点ID
leaf.node <- predict(tree, X[eval, ], type = "node.id")
# 按叶子节点分组，获取每个叶子节点对应的处理策略（唯一值）
action.by.leaf <- unlist(lapply(split(pi.hat, leaf.node), unique))

# 定义一个函数来计算每个叶子节点的统计摘要
# 输入：某个叶子节点对应的双重稳健分数减去成本的值
# 输出：包含平均处理效应减去成本、标准误差和样本量的向量
leaf_stats <- function(leaf) {
  c(ATE.minus.cost = mean(leaf), std.err = sd(leaf) / sqrt(length(leaf)), size = length(leaf))
}

# 合并处理策略规则和按叶子节点分组计算的统计摘要
cbind(
  # 根据处理策略的值，给出对应的处理规则
  rule = ifelse(action.by.leaf == 0, "dont treat", "treat"),
  # 按叶子节点分组，对评估集的双重稳健分数减去成本的值应用统计摘要函数
  aggregate(dr.scores[eval] - cost, by = list(leaf.node = leaf.node),
            FUN = leaf_stats)
)
```

如果要求构建一棵深度为 2 的决策树可能有些难度，那么换一种方式，我们只要求进行一次分割（基于单一协变量的临界值来决定处理与否），结果如下：
```{r}

# 拟合深度为 1 的策略树模型，设置每个叶子节点的最小样本量为 100
tree.depth1 <- policy_tree(X[train, ], dr.rewards[train, ], depth = 1, min.node.size = 100)
# 对评估集数据使用深度为 1 的策略树模型进行预测，并将预测结果减 1，得到处理策略的预测值
pi.hat.eval <- predict(tree.depth1, X[eval, ]) - 1

# 从评估集中筛选出预测应进行处理的样本索引
treat.eval <- eval[pi.hat.eval == 1]
# 从评估集中筛选出预测不应进行处理的样本索引
dont.treat.eval <- eval[pi.hat.eval == 0]

# 计算预测应进行处理的样本子集的平均处理效应
average_treatment_effect(cf, subset = treat.eval)
#> estimate  std.err 
#>      3.9      0.8
# 计算预测不应进行处理的样本子集的平均处理效应
average_treatment_effect(cf, subset = dont.treat.eval)
#> estimate  std.err 
#>      1.8      2.3
```

```{r}
plot(tree.depth1, leaf.labels = c("dont treat", "treat"))
```
![](https://files.mdnice.com/user/91634/b3aed001-ece9-4e0f-9ccb-95899984af6c.png)


## 应用：量化贫困对注意力的影响
在本节中，我们将以Farbmacher等人（2021年）的研究为例，该研究基于Carvalho等人（2016年）的数据进行了因果森林模型的应用。Carvalho等人的实验设计如下：他们随机安排低收入群体在发薪日之前($W=1$)或之后($W=0$)进行认知能力测试，测试结果用于衡量认知功能表现。原始研究未发现平均效应，但Farbmacher团队通过异质性处理效应（HTE）分析发现，证据表明贫困确实会对部分人群的认知功能产生损害。本实验的整理后数据存储在[Github代码库](https://github.com/grf-labs/grf/tree/master/r-package/grf/vignettes/data)中，包含约2500名受试者的观测数据及27项特征（如年龄、收入等）。其中教育程度采用有序变量表示（4：大学毕业生，3：部分大学教育，2：高中毕业生，1：高中以下学历），数值越高代表受教育程度越高。

### 数据概览
```{r}

################################## ex2 ####################################
rm(list = ls())
# 使用 read_csv 函数读取数据，与文件中其他部分保持一致
data <- read_csv("https://raw.githubusercontent.com/grf-labs/grf/master/r-package/grf/vignettes/data/carvalho2016.csv")
glimpse(data)

# 从数据中提取结果变量
Y <- data$outcome.num.correct.ans
# 从数据中提取处理变量
W <- data$treatment
# 从数据中移除前4列，获取特征变量
X <- data[-(1:4)]
```

![](https://files.mdnice.com/user/36552/1348cef0-49bf-4e0b-8aed-631ca41f92c7.png)

该研究据报告采用随机对照试验（RCT）设计，但为确认是否存在无意中忽略的样本重叠问题，我们仍通过估计倾向得分进行验证
```{r}
# 使用回归森林模型预测处理变量 W，设置树的数量为 500
rf <- regression_forest(X, W, num.trees = 500)
# 获取回归森林模型的预测结果
p.hat <- predict(rf)$predictions
# 绘制预测结果的直方图，直观展示预测值的分布
hist(p.hat, main = "回归森林预测值分布", xlab = "预测值", ylab = "频数")
```
![](https://files.mdnice.com/user/91634/e84f97f0-346a-4b28-947e-f72417313154.png)

该数据集包含2,480条观测记录和24个协变量。若在样本量有限的情况下针对如此多的协变量拟合条件平均处理效应(CATE)估计量，很可能导致异质性治疗效果(HTE)检测力度不足。因此，我们首先预测条件均值$E[Y_i | X_i]$，随后采用简化的森林变量重要性分析来筛选在CATE估计阶段需要保留的协变量。
```{r}

# 使用回归森林模型对结果变量 Y 进行预测
Y.forest <- regression_forest(X, Y, num.trees = 500)
# 获取回归森林模型的预测结果
Y.hat <- predict(Y.forest)$predictions

# 计算回归森林模型中各特征变量的重要性
varimp.Y <- variable_importance(Y.forest)

# 保留变量重要性排名前10的变量，用于后续的条件平均处理效应（CATE）估计
keep <- colnames(X)[order(varimp.Y, decreasing = TRUE)[1:10]]
# 输出保留的变量名
keep
```

![](https://files.mdnice.com/user/36552/632bfe54-2461-48ea-b24a-03fe589a1d19.png)

### <!--StartFragment-->

### 使用 TOC 分析异质性

<!--EndFragment-->
```{r}

# 选取变量重要性排名前10的变量构建新特征矩阵
X.cf <- X[, keep]
# 设置处理分配概率的估计值为0.5
W.hat <- 0.5

# 预留前半部分数据用于训练，后半部分用于评估
# （注意：根据预留用于训练/评估的样本不同，结果可能会发生变化）
train <- 1:(nrow(X.cf) / 2)

# 使用训练集数据训练因果森林模型，并传入结果变量和处理变量的预测值
train.forest <- causal_forest(X.cf[train, ], Y[train], W[train], Y.hat = Y.hat[train], W.hat = W.hat)
# 使用训练好的因果森林模型对评估集数据进行预测，获取条件平均处理效应（CATE）的预测值
tau.hat.eval <- predict(train.forest, X.cf[-train, ])$predictions

# 使用评估集数据训练另一个因果森林模型，并传入结果变量和处理变量的预测值
eval.forest <- causal_forest(X.cf[-train, ], Y[-train], W[-train], Y.hat = Y.hat[-train], W.hat = W.hat)

```

与前述研究一致，平均来看似乎没有影响：
```{r}
average_treatment_effect(eval.forest)
#> estimate  std.err 
#>     0.15     0.60
```

![](https://files.mdnice.com/user/36552/a4736c1e-4aef-494f-a8e2-16d8eb242724.png)


```{r}
# 计算评估集因果森林模型中各特征变量的重要性
varimp <- variable_importance(eval.forest)
# 对变量重要性进行降序排序，获取排序后的变量索引
ranked.vars <- order(varimp, decreasing = TRUE)
# 根据变量重要性排序，选取前5个最重要的变量并输出其名称
colnames(X.cf)[ranked.vars[1:5]]
```

![](https://files.mdnice.com/user/36552/9cf75d37-ef60-4bb2-baea-d77f71f9f941.png)

研究结果以认知能力测试中的正确答题数为衡量指标，因此负值的条件平均处理效应(CATE)表明贫困导致了认知能力受损。在计算RATE (AUTOC)时, 我们依据CATE负值最大者优先排序。我们也将年龄因素（从年长到年轻）纳入考量，因为它在被选做分割节点的频率最多。
```{r}
rate.cate <- rank_average_treatment_effect(eval.forest, list(cate = -1 *tau.hat.eval))
rate.age <- rank_average_treatment_effect(eval.forest, list(age = X[-train, "age"]))

par(mfrow = c(1, 2))
plot(rate.cate, ylab = "Number of correct answers", main = "TOC: By most negative CATEs")
plot(rate.age, ylab = "Number of correct answers", main = "TOC: By decreasing age")

```
![](https://files.mdnice.com/user/91634/02036474-2a51-4444-9d46-858874ee178c.png)



          
在代码中使用训练集因果森林模型（train.forest）预测测试集（评估集）的CATE值，主要是为了实现以下目的：

### 1. **模型泛化能力验证**
通过训练集数据构建因果森林模型（train.forest），然后对独立的测试集（评估集）进行CATE预测，能够评估模型在未见过的数据上的泛化能力。这符合机器学习中"训练-验证"分离的基本原则，避免模型对训练数据的过拟合。

### 2. **处理效应异质性评估**
`rank_average_treatment_effect`函数需要基于**预测的CATE值**对样本进行排序，再结合**实际的森林模型**（eval.forest）计算排序后的平均处理效应（TOC曲线）。这种设计可以验证：
- 预测的CATE值是否能有效区分不同处理效应的样本
- 高CATE预测值的样本是否真的具有更高的实际处理效应

### 3. **双重稳健性保障**
代码中同时构建了两个独立的森林模型：
- `train.forest`：用于生成CATE预测（tau.hat.eval）
- `eval.forest`：用于估计实际处理效应
这种分离确保了排序依据（CATE预测）和效应估计（实际模型）的独立性，增强了统计推断的稳健性。

### 关键代码解析
```r:/c:/Users/85330/Desktop/study/广义随机森林-2-GRF导览指南.R
# 使用训练集模型预测测试集CATE
tau.hat.eval <- predict(train.forest, X[-train, ])$predictions

# 基于测试集模型和预测CATE计算TOC曲线
rate.cate <- rank_average_treatment_effect(eval.forest, list(cate = -1 *tau.hat.eval))
```
这里的`-1 * tau.hat.eval`是为了按CATE值**从高到低**排序样本，从而在TOC图中展示优先处理高效应样本时的累积收益。

------------------------------ 

```{r}
rate.cate
#>  estimate std.err       target
#>      -1.5    0.61 cate | AUTOC
rate.age
#>  estimate std.err      target
#>      -1.1    0.68 age | AUTOC
```
此处TOC（处理效应曲线）具有重要参考价值，因为它显示出在较低分位数$q$区间可能存在认知能力下降趋势。Farbmacher等人（2021年）的研究指出，确实有少量人群表现出因贫困导致的负面效应，这种情况正是AUTOC指标在检测异质性时比所谓基尼系数（Qini coefficient）更具统计效力的应用场景。若改用基尼加权方法进行同等评估，所得估计值会显著偏低。

```{r}
qini.cate <- rank_average_treatment_effect(eval.forest, list(cate = -1 *tau.hat.eval), target = "QINI")
qini.age <- rank_average_treatment_effect(eval.forest, list(age = X[-train, "age"]), target = "QINI")

qini.cate
#>  estimate std.err      target
#>     -0.28    0.18 cate | QINI
qini.age
#>  estimate std.err     target
#>     -0.26    0.17 age | QINI
```

##更 多资源

*一些教育资源*

* [Machine Learning & Causal Inference: A Short Course](https://www.youtube.com/playlist?list=PLxq_lXOUlvQAoWZEqhRqHNezS30lI49G-) (video lectures)
机器学习与因果推理：简明课程（视频讲座）

* [Estimating Heterogeneous Treatment Effects in R](https://www.youtube.com/watch?v=YBbnCDRCcAI) (video tutorial)
在 R 中估计异质性处理效应（视频教程）

* [Causal Inference: A Statistical Learning Approach](https://web.stanford.edu/~swager/causal_inf_book.pdf) (textbook)
因果推断：一种统计学习方法（教科书）

* [Estimating Treatment Effects with Causal Forests: An Application](https://doi.org/10.1353/obs.2019.0001) (tutorial paper)
使用因果森林估计处理效应：一个应用（教程论文）

* [Estimating Treatment Effect Heterogeneity in Psychiatry: A Review and Tutorial with Causal Forests](https://doi.org/10.1002/mpr.70015) (tutorial paper)
精神病学中估计处理效应异质性：一个使用因果森林的综述和教程（教程论文）

<center><img src="https://raw.githubusercontent.com/grf-labs/grf/master/images/logo/grf_leaf_green.png" height="64"></center>

## References
Athey, Susan, Julie Tibshirani, and Stefan Wager. "Generalized random forests." The Annals of Statistics 47, no. 2 (2019): 1148-1178.

Breiman, Leo. "Random forests." Machine learning 45, no. 1 (2001): 5-32.

Bruhn, Miriam, Luciana de Souza Leão, Arianna Legovini, Rogelio Marchetti, and Bilal Zia. "The impact of high school financial education: Evidence from a large-scale evaluation in Brazil." American Economic Journal: Applied Economics 8, no. 4 (2016).

Carvalho, Leandro S., Stephan Meier, and Stephanie W. Wang. "Poverty and economic decision-making: Evidence from changes in financial resources at payday." American Economic Review 106, no. 2 (2016): 260-84.

Chernozhukov, Victor, Denis Chetverikov, Mert Demirer, Esther Duflo, Christian Hansen, Whitney Newey, and James Robins. "Double/debiased machine learning for treatment and structural parameters." The Econometrics Journal, 2018.

Efron, Bradley. "Prediction, estimation, and attribution." International Statistical Review 88 (2020): S28-S59. ([link](https://efron.ckirby.su.domains/papers/2019PredictEstimatAttribut.pdf))

Farbmacher, Helmut, Heinrich Kögel, and Martin Spindler. "Heterogeneous effects of poverty on attention." Labour Economics 71 (2021): 102028.

Imbens, Guido W., and Donald B. Rubin. Causal inference in statistics, social, and biomedical sciences. Cambridge University Press, 2015.

Robins, James M., Andrea Rotnitzky, and Lue Ping Zhao. "Estimation of regression coefficients when some regressors are not always observed." Journal of the American Statistical Association 89, no. 427 (1994): 846-866.

Stone, Charles J. "Optimal rates of convergence for nonparametric estimators." The Annals of Statistics (1980): 1348-1360.

Nie, Xinkun, and Stefan Wager. "Quasi-oracle estimation of heterogeneous treatment effects." Biometrika 108, no. 2 (2021): 299-319.

Robinson, Peter M. "Root-N-consistent semiparametric regression." Econometrica: Journal of the Econometric Society (1988): 931-954.

Zheng, Wenjing, and Mark J. van der Laan. "Cross-validated targeted minimum-loss-based estimation." In Targeted Learning, pp. 459-474. Springer, New York, NY, 2011.

Wager, Stefan, and Susan Athey. "Estimation and inference of heterogeneous treatment effects using random forests." Journal of the American Statistical Association 113.523 (2018): 1228-1242.

Yadlowsky, Steve, Scott Fleming, Nigam Shah, Emma Brunskill, and Stefan Wager. "Evaluating Treatment Prioritization Rules via Rank-Weighted Average Treatment Effects." Journal of the American Statistical Association, 120(549), 2025.

Zeileis, Achim, Torsten Hothorn, and Kurt Hornik. "Model-based recursive partitioning." Journal of Computational and Graphical Statistics 17, no. 2 (2008): 492-514.

[1]: `grf`并未真正每个可能的分割点重新拟合线性回归模型——这种操作在计算上是不可行的。取而代之的是，`grf`先在父节点完成*一次*$\hat \tau$的估计，而后基于所谓的"影响函数"进行数学逼近，通过这种方式模拟当样本$i$左子节点移至右子节点时$\hat \tau$的变化量。从算法实现层面来看，这一过程通过GRF论文中详述的"伪残差变换"技术得以完成。

[2]: 关于如何利用Robinson’s transformation构建用于异质处理效应估计的通用损失函数（即 *R-learner*），以及关于$e(x)$和$m(x)$作用的详细说明, 请参见Nie & Wager (2021).

[3]: 请注意$\theta$不必是标量。通过将准则定义为平方 L2 范数$n_L n_R || \hat \tau_L - \hat \tau_R||^2$。同样的构造可用于以向量值目标参数的异质性为目标。这正是 `grf`的多臂因果森林所采用的方法。

[4]: 从技术层面来讲，个体预测值$\hat \tau(x)$的误差过大，而且这些误差在汇总过程中不会相互抵消。

[5]: 该[文档](https://grf-labs.github.io/policytree/reference/policy_tree.html) 说明了这种方法如何有望扩展到更大的数据集（例如，降低 $X_j$ 的基数会减少需要搜索的分割点数量，并有助于降低该方法的计算需求）。