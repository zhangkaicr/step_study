
# GRF导览指南


```{r setup}
library(grf)
```



![](https://files.mdnice.com/user/36552/589c9d27-6da7-4c5e-9d8f-3ca23658ff99.png)




本节简要介绍了 GRF 算法，并包含两个示例应用：1) 金融教育项目的获益分析，2) 衡量贫困对注意力的影响，这些示例将演示如何使用 GRF 来估计条件平均处理效应（conditional average treatment effects, CATEs），使用：
* [best_linear_projection](https://grf-labs.github.io/grf/reference/best_linear_projection.html) 作为简单的线性关系测量方法，它能提供一个 CATEs的低维有效概括，并具备理想的半参数推断特性。 

* [rank_average_treatment_effect](https://grf-labs.github.io/grf/reference/rank_average_treatment_effect.html) (*RATE*) 作为一种通用工具，用于评估异质性和“靶向规则”的有效性，其伴随的 TOC 曲线可帮助识别对处理反应不同的群体子集。

* [policytree](https://github.com/grf-labs/policytree) 用于寻找基于树的策略。


## GRF 概述
本节以*因果森林（Causal Forest）* 的工作原理为例，简要介绍了广义随机森林（Generalized Random Forests, GRF）背后的一些核心概念。首先，阐述了如何利用现代机器学习工具的预测能力，在估计平均治疗效应时进行非参数化的混杂因素控制；然后，说明了如何将布莱曼（Breiman，2001）提出的随机森林重新用于自适应近邻搜索，以检测治疗效应的异质性。


### 机器学习用于因果推断
机器学习算法在预测方面表现出色。然而，在估计治疗效应的背景下，重要的是估计和推断（关于预测与估计之间的根本矛盾，Efron（2020）的文章对此有精彩概述）。下一节将阐述如何通过精心调整并与半参数统计的最佳实践相结合，使现代机器学习能够通过更模型无关的工具来增强因果推断工具箱。

想象一下，我们观察到结果$Y_i$以及二元处理指标$W=\{0, 1\}$， 并希望测量干预对结果的平均因果效应。如果我们并非处于随机对照试验环境中，但收集了一组我们认为能够合理解释混杂因素的协变量$X_i$ 那么我们可以进行如下类型的回归（Imbens & Rubin, 2005）
$$
Y_i \sim \tau W_i + \beta X_i,
$$
并将估计的$\hat \tau$ 解释为平均处理效应$\tau = E[Y_i(1) - Y_i(0)]$的估计, 其中$Y_i(1), Y_i(0)$是对应于两种处理状态的可能结果。如果满足以下条件，这种方法是合理的：

1) $W_i$在给定$X_i$的情况下是无混杂的（即，在控制协变量的情况下，处理效果等同于随机分配）。
2) 混杂因素$X_i$对$Y_i$具有线性效应。
3) 处理效应$\tau$是恒定的。

假设 1）是一个我们必须接受的“识别性”假设，而 2）和 3）是我们可以质疑的建模假设。让我们从假设 2）开始：这是一个很强的参数化建模假设，它要求混杂因素对结果具有线性影响，而我们应该能够借助半参数统计来放宽这一假设。

**放宽假设2)**. 我们可以转而提出部分线性模型:

$$
Y_i = \tau W_i + f(X_i) + \varepsilon_i, \, \, E[\varepsilon_i | X_i, W_i] = 0,
$$
其中，我们假设一个个体的基线结局由某个未知的（可能是复杂的）函数$f$给出, 而处理分配会使结局产生一个恒定的偏移量$\tau$。但在不了解$f(X_i)$的情况下如何估计$\tau$呢? Robinson (1988)指出，如果我们定义以下两个中间对象，倾向性评分：
$$
e(x) = E[W_i | X_i=x],
$$
和$Y$的条件均值：
$$
m(x) = E[Y_i | X_i = x] = f(x) + \tau e(x),
$$
那么我们可以将上述方程改写成“中心化”形式：

$$
Y_i - m(x) = \tau (W_i - e(x)) + \varepsilon_i.
$$
这种公式具有很强的实际吸引力，因为它意味着可以通过残差对残差的回归来估计$\tau$ : 输入$m(x)$和$e(x)$的估计值，然后将中心化的结局对中心化的处理指标进行回归。 Robinson (1988) 指出，这种方法能得出$\tau$的根号n一致估计, 即使$m(x)$和$e(x)$的估计值收敛速度较慢(尤其是"四次方根" )。 这一性质通常被称为*正交性* ，它是一种理想的性质，本质上表明：即便存在有噪声的 “干扰项” 估计值($m(x)$和$e(x)$) 你仍然能够得到目标参数($\tau$)的 “良好” 估计值。

但你应该如何估计 $m(x)$和$e(x)$呢？难道你仍然必须设定一个参数模型（例如，用逻辑回归来估计倾向得分）吗？这正是现代机器学习工具库发挥作用的地方—— 因为我们意识到，对于$m(x)$和$e(x)$，我们只需要在给定$X_i$的条件下，对结局和处理分配进行良好的*预测*即可。而这类问题正是 提升（boosting）、随机森林等现代机器学习方法所擅长的。直接将$m(x)$和$e(x)$的估计值代入残差回归中，通常会导致偏差，因为现代机器学习方法会正则化以权衡偏差和方差。然而，Zheng & van der Laan (2011) 和 Chernozhukov 等人 (2018) 指出，如果你以“交叉拟合”的方式形成这些估计值 —— 即对第 i 个观测值的结局和处理分配的预测在估计过程中不使用第 i 个样本 —— , 那么 (在满足某些正则性假设的情况下) 仍然可以得到$\tau$的根号n一致估计.

因此，到目前为止总结一下：我们有一种方法可以利用现代机器学习工具库，在估计平均治疗效应时进行非参数化的混杂因素控制，同时仍能保持无偏性和一致性等理想的统计性质。

**非恒定处理效应**. 非恒定治疗效应。如果我们想放宽假设 3）该怎么办？我们可以指定某些亚组，为每个亚组单独进行回归，从而得到不同的$\tau$的估计值. 这种方法要求我们在查看数据之前指定潜在的亚组。我们如何利用数据来了解潜在的亚组？我们可以继续使用上述 Robinson 的部分线性模型，转而假设：
$$
Y_i = {\color{red}\tau(X_i)}W_i + f(X_i) + \varepsilon_i, \, \, E[\varepsilon_i | X_i, W_i] = 0,
$$
$\color{red}{\tau(X_i)}$ 是平均处理效应$E[Y(1) - Y(0) | X_i = x]$. 我们要如何估计它？ 假设我们能找到某个邻域$\mathcal{N}(x)$其中$\tau$是恒定的， 那么我们可以完全按照之前的方法，对属于$\mathcal{N}(x)$的样本进行残差对残差的回归，即：
$$
\tau(x) := lm\Biggl( Y_i - \hat m^{(-i)}(X_i) \sim W_i - \hat e^{(-i)}(X_i), \text{weights} = 1\{X_i \in \mathcal{N}(x) \}\Biggr),
$$
(上标$^i$表示交叉拟合估计)。这在概念上正是*因果森林*的原理： 它通过对具有相似治疗效应的样本进行加权残差对残差回归，来估计目标样本$X_i = x$的处理效应$\tau(x)$。 这些*权重*起着关键作用，那么广义随机森林（`grf`）是如何找到他们的呢？下一节将简要回顾Breiman的回归随机森林，然后说明如何将其扩展为自适应邻域搜索器。

### 随机森林作为自适应邻域搜索器

Breiman用于预测条件均值$\mu(x) = E[Y_i | X_i = x]$的随机森林可以简要总结为两个步骤： 

1)构建阶段：构建$B$棵树，通过贪婪选择协变量分割点，使子组均值的平方差$n_L n_R (\bar y_L - \bar y_R)^2$最大化。
2)预测阶段：汇总每棵树的预测结果以形成最终的点估计，通过平均落入与目标样本$x$相同的终端叶节点$L_b(X_i)$中的结果$Y_i$，形成最终点估计：$\hat \mu(x) = \frac{1}{B} \sum_{b=1}^{B} \sum_{i=1}^{n} \frac{Y_i 1\{Xi \in L_b(x)\}} {|L_b(x)|}$

![](https://files.mdnice.com/user/91634/2c1bec8e-092d-4326-b6a2-295acc81dfdb.png)
图 1

对于单棵树和单次分割，图 1 展示了阶段 1)中的最优分割点：这条竖线会使左侧和右侧的$Y_i$均值尽可能不同（或者说，使均值的平方差尽可能大）。

图 1 中，我们希望预测的目标样本$x$在右侧叶节点中以加号表示。阶段 2)会对该侧的$Y_i$取平均值，然后对其余的$B$棵树重复同样的操作，在对这些结果取平均值，从而得出最终预测值。这一过程是双重求和，先对树求和，再对训练样本求和。我们可以交换求和顺序，得到：
$$
\begin{equation*}
\begin{split}
& \hat \mu(x) = \sum_{i=1}^{n} \frac{1}{B} \sum_{b=1}^{B} Y_i \frac{1\{Xi \in L_b(x)\}} {|L_b(x)|} \\
& = \sum_{i=1}^{n} Y_i \color{blue}{\alpha_i(x)},
\end{split}
\end{equation*}
$$
其中，我们将$\color{blue}{\alpha_i(x)}$定义为第$i$个训练样本与$x$落入同一叶子节点的频率. 也就是说，随机森林预测阶段的另一种等效描述是，它预测的是结果的加权平均值。这些权重就是所谓的随机森林自适应邻域权重，它们反映了目标样本$x$与每个训练样本$X_i$, $i = 1 \ldots n$的"相似程度" (这种对随机森林的加权视角在随机森林的统计应用中经常出现，例如可参见 Zeileis、Hothorn 和 Hornik（2003）的研究).

**因果森林** 本质上通过修改上述步骤，结合了 Breiman（2001）和 Robinson（1988）的思想：

1) 构建阶段：贪婪地设置协变量分割点，以最大化子组处理效应的平方差$n_L n_R (\hat \tau_L - \hat \tau_R)^2$,其中$\hat \tau$是通过对每个可能的分割点运行罗宾逊（Robinson）的残差对残差回归得到的[1]。
2) 使用得到的森林权重$\color{blue}{\alpha(x)}$来估计


$$
\tau(x) := lm\Biggl( Y_i - \hat m^{(-i)}(X_i) \sim W_i - \hat e^{(-i)}(X_i), \text{weights} = \color{blue}{\alpha_i(x)} \Biggr).
$$
也就是说,*因果森林*运行的是Robinson的回归的 “森林” 局部版本。这种自适应加权（而非叶子节点平均）方法，再结合其他一些被称为 “诚实性（honesty）”和“子抽样（subsampling）” 的森林构建细节，可用于为随机森林的估计和推断提供渐近保证（Wager & Athey, 2018）。在函数`causal_forest`中,参数 `Y.hat` 和 `W.hat` 提供了$m(x)$和$e(x)$的估计,默认情况下，这些估计值是通过单独的回归森林得到的[2]。

我们上文概述的方法可以进行推广（因此得名*广义* 随机森林）以估计异质性处理效应之外的其他量。其核心要素是上文的阶段 1）因为我们发现Robinson的回归可以等效地表示为一种由特定得分函数$\psi_{\tau}(\cdot)$给出的 “估计方程” 形式。广义随机森林（Athey, Tibshirani & Wager, 2019） 将阶段1）进行推广，以针对某个任意参数中的异质性，该参数被定义为这个估计方程的解。也就是说，广义随机森林本质上接收的输入是：在*没有*协变量的情况下如何估计某个参数[3] $\theta$的公式（以得分函数 $\psi$的形式呈现)，然后找到森林权重${\alpha(x)}$，从而得到特定于*协变量*的估计值 $\theta(x)$.

### 高效估计条件平均处理效应（conditional average treatment effects, CATEs）的汇总统计量
到目前为止，我们已经阐述了罗宾逊的残差对残差回归如何满足正交性性质 —— 即尽管干扰项($m(x)$和$e(x)$)的估计速度较慢，但目标参数$\tau(x)$仍能得到较好的估计。这是估计方程$\psi$的一个理想性质，尤其是当我们希望使用机器学习方法估计干扰项时（这类方法虽然比参数模型更灵活，但收敛速度较慢）(Stone, 1980)。 那么，对于 $\tau(x)$的汇总统计量的估计，例如平均处理效应（ATE）或最佳线性投影（BLP）等估计量，如何保证其具有根号n收敛速度以及精确的置信区间呢？

结果表明，存在比简单地对因果森林得到的$\hat \tau(x)$值取平均值更好的方法[4]。Robins, Rotnitzky & Zhao (1994)指出，所谓的增强逆概率加权（AIPW）估计量对于$\tau$而言是渐近最优的 (即在所有非参数估计量中，它具有最小的方差)。其形式如下：

$$
\hat \tau_{AIPW} = \frac{1}{n} \sum_{i=1}^{n}\left( \mu(X_i, 1) - \mu(X_i, 0) + W_i \frac{Y_i - \mu(X_i, 1)}{e(X_i)} - (1 - W_i)\frac{Y_i - \mu(X_i, 0)}{1 - e(X_i)} \right),
$$
其中$\mu(X_i, 1),  \mu(X_i, 0)$是两个处理组中条件均值的估计量：$\mu(X_i, W_i) = E[Y_i | X_i = x, W_i = w]$。该表达式可重新整理并表示为：


$$
\frac{1}{n} \sum_{i=1}^{n}\left( \tau(X_i) + \frac{W_i - e(X_i)}{e(X_i)[1 - e(X_i)]} \left(Y_i - \mu(X_i, W_i)\right) \right) \\
= \frac{1}{n} \sum_{i=1}^{n} \Gamma_i.
$$
我们可以将这三个项分别识别为：1）初始处理效应估计值$\tau(X_i)$, 2）去偏权重$\frac{W_i - e(X_i)}{e(X_i)[1 - e(X_i)]}$,以及3）残差  a residual $Y_i - \mu(X_i, W_i)$.如果我们用因果森林得到的非参数干扰项估计值（在满足某些正则条件的前提下，如交叉拟合，参见 Zheng & van der Laan (2011)、Chernozhukov 等人 (2018) 的研究）来替代这个插补构造，其渐近有效性仍然成立。

一般来说，上述构造会产生所谓的**双重稳健**估计方程，这也是`grf` 在计算平均处理效应（ATE）、最佳线性投影（BLP）和 “RATE” 等汇总统计量时所采用的方法。相关的双重稳健得分$\hat \Gamma_i$ 可通过函数`get_scores`获取。 具体而言，平均处理效应（ATE）是$\hat \Gamma_i$的平均值而最佳线性投影（BLP）则是将$\hat \Gamma_i$对一组协变量$X_i$进行回归的结果。基于这些得分构建的汇总统计量，在解释非参数 CATE 估计结果时起着关键作用，因为受非参数估计（包括机器学习）的基本限制，CATE 的点估计往往具有*噪声*。接下来的两节将通过应用案例进行说明。


## 应用：学校项目评估
在本节中，我们将介绍一个广义随机森林（GRF）的实际应用案例。我们使用的数据来自 Bruhn 等人（2016）的研究，该研究在巴西开展了一项随机对照试验（RCT），其中高中被随机分配参与一项金融教育项目（在这类研究中，为避免学生层面的干扰，通常会在学校层面进行随机分配）。该项目总体上提高了学生的金融素养。论文中还探讨了其他结果指标，在此我们重点关注金融素养得分。经过处理的数据集（包含约 17000 名学生的个人数据）存储在[GitHub 代码库](https://github.com/grf-labs/grf/tree/master/r-package/grf/vignettes/data/)中，其中提取了学生的基本特征，以及我们用作协变量的其他基线调查应答数据（作者将其中两项数据汇总为一个指数，用于评估学生的储蓄能力和财务自主性）。

*符号说明*：在整个过程中，我们使用变量名`Y`和`W` 表示结果和二元处理分配，使用`Y.hat`表示 $E[Y_i | X_i = x]$的估计值, `W.hat`表示$E[W_i | X_i = x]$的估计值，以及`tau.hat`表示$\tau(X_i) = E[Y_i(1) - Y_i(0) | X_i = x]$的估计值。

### 数据概览
```{r}
library(tidyverse)
library(grf)

rm(list = ls())
# 注意：直接从GitHub读取文件需要使用raw.githubusercontent.com
# 我们需要修改URL以指向原始文件
# 文件原始目录：https://github.com/grf-labs/grf/blob/master/r-package/grf/vignettes/data/bruhn2016.csv

data <- read_csv("https://raw.githubusercontent.com/grf-labs/grf/master/r-package/grf/vignettes/data/bruhn2016.csv")
head(data)
colnames(data)

# 从数据中提取结果变量
Y <- data$outcome.test.score
# 从数据中提取处理变量
W <- data$treatment
# 从数据中提取学校变量
school <- data$school
# 从数据中移除前3列，获取特征变量
X <- data[-(1:3)]

# 大约30%的数据存在一个或多个缺失的协变量，处理组和对照组之间的缺失模式似乎没有系统性差异，
# 由于广义随机森林(GRF)支持对存在缺失值的特征变量进行划分，因此我们将这些数据保留在分析中。
# 计算特征变量中包含缺失值的行数占比
sum(!complete.cases(X)) / nrow(X)

# 进行t检验，查看处理组和是否有缺失值之间是否存在显著差异
t.test(W ~ !complete.cases(X))

```

![](https://files.mdnice.com/user/36552/25fb3e83-0be7-4535-8751-6ec7e8790a4b.png)

### 估计和汇总条件平均处理效应（CATEs）
自始至终，我们都将倾向得分固定为 `W.hat = 0.5`因为我们知道这是一项随机对照试验(否则，我们会为 `W.hat`拟合一个倾向模型, 并通过检查估计概率的直方图来评估重叠假设的合理性).
```{r}
cf <- causal_forest(X, Y, W, W.hat = 0.5, clusters = school)
```

![](https://files.mdnice.com/user/36552/7f82af3a-4275-467a-84ec-06159340f195.png)



计算双重稳健的平均处理效应（ATE）估计值。
```{r}
# 计算平均处理效应（Average Treatment Effect, ATE）
ate <- average_treatment_effect(cf)
# 输出平均处理效应的结果
ate["estimate"]/sd(Y)
# 0.3为金标准
```

![](https://files.mdnice.com/user/36552/36ee3ac4-27ec-4419-9a54-520e145839ee.png)





与总体结果量表相比，这种益处似乎相当显著：`ate[1] / sd(Y)` = 0.3，这与 Bruhn 等人（2016）的研究结果一致。

一种非常简单的方法可以查看哪些变量似乎对处理效应有影响，那就是查看变量重要性`variable_importance`，它衡量了变量$X_j$<!--StartFragment-->被用于分割的频率。<!--EndFragment-->
```{r}
varimp <- variable_importance(cf)
ranked.vars <- order(varimp, decreasing = TRUE)

# Top 5 variables according to this measure
colnames(X)[ranked.vars[1:5]]

```

![](https://files.mdnice.com/user/36552/0ffdda00-2822-48e5-a6db-7f56ac46068b.png)

对条件平均处理效应（CATEs）进行简单易懂的汇总度量方式是[最佳线性投影](https://grf-labs.github.io/grf/reference/best_linear_projection.html)，它为线性模型提供了双重稳健的估计。

$$\tau(X_i) = \beta_0 + A_i \beta,$$
其中$A_i$是一个协变量向量。 如果我们将$A$设置为具有最高变量重要性的协变量，我们就可以估计 CATEs 的一个简单线性关联度量：

```{r}
best_linear_projection(cf, X[ranked.vars[1:5]])
```

![](https://files.mdnice.com/user/36552/5d405117-4b1c-464c-8367-8bb5dda7d77b.png)




          
### `best_linear_projection` 函数解析：用法与统计意义

#### 一、函数基本用法
在`grf`包中，`best_linear_projection`用于将**条件平均处理效应（CATE）** 投影到线性空间，揭示协变量与处理效应的线性关系。其核心语法为：
```r
best_linear_projection(forest_object, covariates)
```
- **第一个参数**：已训练的因果森林对象（如`causal_forest`返回结果）
- **第二个参数**：用于投影的协变量矩阵（如用户代码中的`X[ranked.vars[1:5]]`表示前5个重要变量）

#### 二、数学原理与统计意义
本质是找到最接近非线性CATE函数的线性近似，实现：
1. **维度压缩**：将高维非线性效应降维为可解释的线性系数
2. **统计推断**：提供系数的稳健标准误和p值（基于HC3异方差稳健估计）
3. **效应方向判断**：通过系数符号判断协变量对处理效应的调节方向

#### 三、用户代码解析
```r
# 使用前5个最重要的特征变量，对因果森林模型进行最佳线性投影
best_linear_projection(cf, X[ranked.vars[1:5]])
```
- **`cf`**：因果森林对象（已通过`causal_forest()`训练）
- **`X[ranked.vars[1:5]]`**：选取按重要性排序的前5个协变量
- **输出结果**：类似线性回归的系数表，包含：
  - 截距项：平均处理效应的基准水平
  - 各协变量系数：表示该变量每增加1单位，CATE的平均变化量
  - 稳健p值：判断协变量对处理效应的调节作用是否统计显著

#### 四、实际应用价值
1. **效应异质性分析**：识别哪些协变量显著调节处理效应（如"年龄每增加10岁，治疗效果降低0.2个单位"）
2. **模型简化**：用线性关系近似复杂的非线性效应，便于结果汇报
3. **变量选择验证**：通过p值检验重要变量（如用户选择的top5变量）是否真的具有调节作用

#### 五、与传统方法的区别
| 方法               | 特点                                  | 优势                                  |
|--------------------|---------------------------------------|---------------------------------------|
| 普通线性回归       | 直接假设CATE线性                      | 简单但可能 miss 非线性关系            |
| `best_linear_projection` | 先非参数估计CATE再线性投影 | 保留非线性信息同时获得可解释性        |



#### 六、注意事项
1. **变量选择**：建议仅使用经变量重要性分析筛选的协变量（如用户代码中的`ranked.vars`）
2. **稳健性**：默认提供HC3稳健标准误，无需额外假设同方差性
3. **局限性**：无法捕捉高阶交互效应，复杂非线性关系可能需要分段投影

--------------------------
        


研究最佳线性投影（best linear projection，BLP）后发现，“财务自主指数” 较高的学生从干预中获益较少。随机对照试验的作者们解释道，这是一个“基于心理学的财务自主指数”，它汇总了一系列问题，用于衡量学生是否感到有能力、有信心做出独立的财务决策，以及是否能影响家庭的财务决策”。最佳线性投影似乎表明，根据该指数衡量已具备良好财务状态的学生，从这一培训课程中获益不多。

### 用排序平均处理效应（rank average treatment effect，RATE）评估条件平均处理效应（CATE）估计值
因果推断从根本上来说，比机器学习算法的典型预测性应用更具挑战性，因为后者有明确的评分指标（如预测误差）。处理效应本质上是无法直接观测的，因此我们需要替代指标来评估其表现。Nie 和 Wager（2021）所探讨的*R-loss*就是这样一种指标，例如，它可作为交叉验证的标准，但无法告诉我们是否存在异质性处理效应（HTEs）。尽管真实的处理效应无法观测，但我们可以利用对预留数据（held out data）的处理效应的适当*估计*来评估模型。*排序加权平均处理效应*([RATE](https://grf-labs.github.io/grf/reference/rank_average_treatment_effect.html))(Yadlowsky et al., 2025)是一种评估CATE估计器在按估计处理收益对个体进行排序时表现的指标。它可以被视为衡量异质性的一种曲线下面积（AUC）度量，数值越大表示表现越好。

RATE具有一个直观的可视化特征：它是一条曲线下的面积，该曲线描绘了在改变处理比例 $q \in [0, 1]$时，以下期望值的差异:
$$TOC(q) = E[Y_i(1) - Y_i(0) | \hat \tau(X_i) \geq F^{-1}_{\hat \tau(X_i)}(1 - q)] - E[Y_i(1) - Y_i(0)],$$

（$F(\cdot)$ 是分布函数）。也就是说，在$q = 0.2$时， TOC量化了仅对估计 CATE 最大的 20% 个体进行处理，相较于整体平均处理效应（ATE）所带来的增量收益。我们将 TOC 下方的面积称为 *AUTOC* 此外还有其他 RATE（排序加权平均处理效应）指标，例如 *Qini 系数*，它对 TOC 下方的面积采用了不同的加权方式。

使用 RATE 进行有效推断的一个方法是，将数据分为训练集和评估集，一个用于评估 RATE，另一个用于训练 CATE 估计器。这种方法的缺点是，我们可能会根据用于定义评估集和训练集的随机样本检测到不同的结果。由于随机对照试验是在学校层面进行的聚类，我们将在学校层面抽取随机单位：
```{r}

# 按学校对样本进行分组，将样本索引按照学校变量进行分割
samples.by.school <- split(seq_along(school), school)
# 计算学校的数量
num.schools <- length(samples.by.school)
# 随机抽取一半的学校，将这些学校对应的样本索引合并为训练集
train <- unlist(samples.by.school[sample(1:num.schools, num.schools / 2)])
# 使用训练集数据训练因果森林模型
train.forest <- causal_forest(X[train, ], Y[train], W[train], W.hat = 0.5, clusters = school[train])
# 使用训练好的因果森林模型对非训练集数据进行预测，获取条件平均处理效应（CATE）的预测值
tau.hat.eval <- predict(train.forest, X[-train, ])$predictions

# 使用非训练集数据训练另一个因果森林模型
eval.forest <- causal_forest(X[-train, ], Y[-train], W[-train], W.hat = 0.5, clusters = school[-train])

# 基于评估森林模型和预测的 CATE 值，计算排序后的平均处理效应
rate.cate <- rank_average_treatment_effect(eval.forest, tau.hat.eval)
# 绘制排序后的平均处理效应图，图标题为 "TOC: By decreasing estimated CATE"
plot(rate.cate, main = "TOC: By decreasing estimated CATE")
# 输出排序后的平均处理效应结果
rate.cate
```
![](https://files.mdnice.com/user/91634/f1a448ec-8cd9-4804-b74a-cec039e17104.png)
具体到这个数据集，排序加权平均处理效应（RATE）是否显著，取决于条件平均处理效应（CATE）估计器是否在具有足够信号的子样本上训练（使用不同的方法，例如 boosting或惩罚线性模型来训练 `Y.hat`的模型有时会很有用）。 除了用于 CATE 排序之外，RATE 指标还有更多应用方式。例如，我们可以通过某一特定变量的排序来计算TOC。上一部分提到，财务自主性较高的学生从该项目中获益较少。我们可以利用 RATE 来评估基于这一指数对学生进行优先级排序的效果：

```{r}
# 由于我们要基于某个协变量计算排序平均处理效应(RATE)，因此使用在全量数据上训练好的森林模型
rate.fin.index <- rank_average_treatment_effect(
  cf,
  -1 * X$financial.autonomy.index, # 乘以 -1 以便按指数降序排序
  subset = !is.na(X$financial.autonomy.index) # 忽略 X 中值为缺失的数据
  )
# 绘制排序平均处理效应图，设置 x 轴标签为 "处理比例"，y 轴标签为 "测试分数提升"，图标题为 "TOC: 按财务自主权增加排序"
plot(rate.fin.index, xlab = "Treated fraction", ylab = "Increase in test scores", main = "TOC: By increasing financial autonomy")


```
![](https://files.mdnice.com/user/91634/4a2b33a4-def1-461a-a448-e930d78d2374.png)
```{r}
rate.fin.index
#>  estimate std.err             target
#>      0.69    0.22 priorities | AUTOC
```

TOC表明，财务自主指数较低的学生从该项目中获得的收益高于平均水平，且AUTOC在常规水平上具有显著性：`rate.fin.index$estimate / rate.fin.index$std.err` = 3.08。与结果的标准差`sd(Y)` = 14.74相比，这一收益也显得具有实际意义。


# 科研合作及科研服务项目介绍-v0.5

1. 方法学实现语言：R语言，Python，SPSS，PASS(样本量计算)

2. 服务形式：科研方案设计及方法学指导，数据分析及图表制作，可开发票，具体情况可联系助教程老师

3. 可进行科研合作，具体请联系助教

![助教微信-程老师](https://files.mdnice.com/user/36552/42b3702f-74f0-4ad8-8ff1-c36656a37150.jpg)


# 部分内容说明


## 因果推断/真实世界研究/临床研究

- 1.多重插补后组间基线表SMD-标准化差异率对比
- 2.多组的倾向性评分匹配及逆概率加权实现，有向无环图的绘制及解释（DAG）
- 3.亚组分析及亚组交互作用P值计算并绘制图表
- 4.生存数据永恒时间偏倚的克隆删失加权法实现及设计
- 5.基于界标法的区段生存分析（landmark survival analysis）
- 6.基于联合法或界标法的动态预测模型构建及验证
- 7.机器学习预测模型的（二分类及生存）的构建与验证
- 8.限制性立方样条确定非线性效应截断值并进行区段回归分析（piecewise regression ）
- 9.潜类别分析
- 10.规则关联分析
- 11.面板数据分析
- 12.纵向数据分析（广义线性混合模型，广义估计方程，多变量重复测量方差分析）
- 17.目标试验模拟分析及试验设计
- 18.G参数法进行纵向数据分析（g formula）
- 19.多层级倾向性评分处理多中心PSM情况(Multi-cluster PSM)
- 20.重叠加权及后续效应值估计（包括生存分析）
- 21.治疗效果异质性敏感性分析（PATH）-内科学年鉴方法
- 22.基于反事实推定的治疗异质性分析
- 23.机器学习因果推断

## 文献计量学分析及图表解释

- 1.协助制定检索策略并进行相关文献检索下载元数据
- 2.文献分布情况整体分析，包括引用情况分析
- 3.基于关键词的动态分析及可视化
- 4.核心作者及核心国家分析，包括合作关系网络分析
- 5.核心杂志鉴定及动态变化分析
- 6.全局及局部核心文献鉴定
- 7.关键词动态变化分析及主题凸现分析


## 人工智能类研究

- 1.结构化数据机器学习的批量建模及最优模型选择-mlr3/pycaret
- 2.结构化数据生存数据的批量建模及最优模型的选择
- 3.传统影像组学特征提取及后续基于机器学习的分析全流程分析
- 4.机器学习及深度学习模型可解释方法学实现（shap/lime/迭代法等）
- 5.各种变量筛选方法的实现（RLE/重要性/过滤法/包装法等）
- 6.基于CNN的医学影像数据的深度学习方法学实现
- 7.CT/MRI/超声等医学影像学数据的传统影像组学分析
- 8.CT/MRI/超声等医学影像学数据的深度学习

## 生物信息学分析

- 1.传统转录组差异-富集分析
- 2.反卷积及细胞比例鉴定分析
- 3.SNP相关分析
- 4.CNV相关分析
- 5.甲基化数据相关分析
- 3.单细胞降维、聚类及细胞鉴定
- 4.单细胞轨迹分析及细胞速率分析


### 欢迎关注我的视频号-**定期直播免费文献分享会**


![扫一扫，添加我的视频号](https://files.mdnice.com/user/36552/bb758dda-5031-48df-a061-51f549c5b61b.jpg)



### 欢迎关注我的B站账号-**公开课及文献分享视频会更新至此**



![我的B站](https://files.mdnice.com/user/36552/167c6dc1-6d6e-40b3-b6c8-3379489d5c2e.jpg)

